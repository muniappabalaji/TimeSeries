{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muniappabalaji/TimeSeries/blob/main/LLM/RAG/PineCone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyzqDoa_eKs2",
        "outputId": "1a14c419-826c-4bd1-fc6d-07ef2c49e4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/587.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/587.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pinecone pinecone-client sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google.colab import userdata\n",
        "import time"
      ],
      "metadata": {
        "id": "J6q6_jPcesnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely get the API key from Colab secrets\n",
        "try:\n",
        "    PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERROR: PINECONE_API_KEY not found in Colab secrets.\")\n",
        "    print(\"Please follow Step 1 in the instructions to add your key.\")\n",
        "    # Exit the script if the key is not found\n",
        "    exit()"
      ],
      "metadata": {
        "id": "N4RBQaQsew5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"colab-quickstart\"\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "print(f\"--- Pinecone initialized for index: '{index_name}' ---\")"
      ],
      "metadata": {
        "id": "_8UlZeJ9fNtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "# This model creates 384-dimensional vectors\n",
        "embedding_dim = model.get_sentence_embedding_dimension()\n",
        "\n",
        "# Check if the index already exists. If not, create it.\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    print(f\"Index '{index_name}' not found. Creating a new one...\")\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=embedding_dim,\n",
        "        metric=\"cosine\", # Cosine similarity is great for semantic search\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1') # Use ServerlessSpec directly\n",
        "    )\n",
        "    # Wait for the index to be ready\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "    print(f\"--- Index '{index_name}' created successfully with dimension {embedding_dim} ---\")\n",
        "else:\n",
        "    print(f\"--- Index '{index_name}' already exists. Connecting to it. ---\")\n",
        "\n",
        "# Connect to your index\n",
        "index = pc.Index(index_name)\n",
        "print(\"\\nIndex Stats:\")\n",
        "print(index.describe_index_stats())"
      ],
      "metadata": {
        "id": "R-J7JMcJfRgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"The capital of France is Paris, a city known for its art and culture.\",\n",
        "    \"Photosynthesis is the process by which plants use sunlight to create food.\",\n",
        "    \"The Python programming language is widely used for web development and data science.\",\n",
        "    \"Mount Everest is the Earth's highest mountain above sea level.\",\n",
        "    \"A black hole is a region of spacetime where gravity is so strong that nothing can escape.\"\n",
        "]\n",
        "\n",
        "# Generate embeddings (vectors) for each document\n",
        "print(\"\\n--- Creating vector embeddings for our documents ---\")\n",
        "embeddings = model.encode(documents)"
      ],
      "metadata": {
        "id": "2NQJXK24gsCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_to_upsert = []\n",
        "for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
        "    vectors_to_upsert.append(\n",
        "        (f\"doc_{i}\", emb.tolist(), {\"text\": doc})\n",
        "    )\n",
        "\n",
        "print(\"\\n--- Upserting vectors into the Pinecone index ---\")\n",
        "index.upsert(vectors=vectors_to_upsert)\n",
        "\n",
        "print(\"\\nUpsert complete. New Index Stats:\")\n",
        "print(index.describe_index_stats())"
      ],
      "metadata": {
        "id": "GP5O3A0HgvDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PERFORMING SEMANTIC SEARCH\")\n",
        "\n",
        "query = \"What is the name of the tallest mountain?\"\n",
        "\n",
        "# 1. Create the vector embedding for the query\n",
        "query_embedding = model.encode(query).tolist()\n",
        "\n",
        "# 2. Query Pinecone to find the most similar vectors\n",
        "results = index.query(\n",
        "    vector=query_embedding,\n",
        "    top_k=2, # Return the top 2 most similar results\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "# 3. Print the results\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Top Results:\")\n",
        "for match in results['matches']:\n",
        "    score = match['score']\n",
        "    text = match['metadata']['text']\n",
        "    print(f\"  - Score: {score:.4f}\")\n",
        "    print(f\"    Text: {text}\\n\")"
      ],
      "metadata": {
        "id": "yZTZhRwPhBLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Cleaning up. Deleting the index... ---\")\n",
        "pc.delete_index(index_name)\n",
        "print(f\"Index '{index_name}' has been deleted.\")"
      ],
      "metadata": {
        "id": "Yz5HPHwuhM9v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}